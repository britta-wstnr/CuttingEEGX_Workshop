{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining channel types for source reconstruction\n",
    "\n",
    "\n",
    "`\n",
    "Author: Britta Westner\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will have a look at combining different sensor types for beamformer source reconstruction. We first combine MEG magnetometers and gradiometers, and later we also include EEG channels. We use the `sample` dataset, which is a simultaneous MEG-EEG recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import mne\n",
    "\n",
    "mne.set_log_level('warning')\n",
    "\n",
    "# set paths:\n",
    "sample_path = mne.datasets.sample.data_path()\n",
    "data_path = sample_path / 'MEG' / 'sample'\n",
    "subjects_dir = sample_path / 'subjects'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read raw and re-reference EEG to the average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we read the raw data from disk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_raw = data_path / 'sample_audvis_raw.fif'\n",
    "raw = mne.io.read_raw_fif(fname_raw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For the source reconstruction of EEG data, it's vital to use an **average reference**. To learn more about this, you can check out the notebook `Source_reconstruction_with_EEG.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the average reference for the EEG data\n",
    "raw.set_eeg_reference(ref_channels='average', projection=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute epochs\n",
    "\n",
    "Next, we want to create epochs from the continuous data. We do not compute the evoked responses yet - before we do this, we might first want to pick the data. That means, we want to choose which channels stay in the data and which get dropped.\n",
    "We use the epochs where a visual stimulus was presented in the left or right visual field. These have the trigger codes `3` and `4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = mne.find_events(raw)\n",
    "epochs = mne.Epochs(raw, events, event_id=[3, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beamforming with MEG gradiometers and magnetometers\n",
    "\n",
    "First, we will compute a beamformer source reconstruction using only the MEG data. This dataset was measured using a MEGIN/Elekta system which has two MEG sensor types: magnetometers and gradiometers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MEG forward model\n",
    "\n",
    "Due to the time constraints of the workshop, we load the forward model from disk. The MEG forward model for the `sample` dataset contains all information for the gradiometers _and_ magnetometers.\n",
    "\n",
    "If you want to learn more about how to compute forward models, check out the notebook `Forward_modelling.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the precomputed EEG forward model from disk\n",
    "fname_fwd = data_path / 'sample_audvis-meg-oct-6-fwd.fif'\n",
    "fwd_meg = mne.read_forward_solution(fname_fwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick the epochs and compute the evoked fields\n",
    "\n",
    "We now create a copy of the epochs that only contains the two MEG sensor types, magnetometers and gradiometers. From those epochs, we create the evoked fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_meg = epochs.load_data().copy().pick(picks=['mag', 'grad'])\n",
    "evoked_meg = epochs_meg.average()\n",
    "evoked_meg.plot_joint();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute covariance matrices from MEG data\n",
    "\n",
    "For the computation of the beamformer, we need a **data covariance matrix**. Let's compute our covariance matrix over the first 150 ms after the stimulus was presented.\n",
    "\n",
    "Because we are dealing with two sensor types, we also need a **noise covariance matrix**. It will be used to **whiten** the data and covariance matrix (and forward model). The most important thing this achieves is that the scaling of the sensors is adapted between the sensor types. \n",
    "The noise covariance matrix is computed using the baseline of the epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Combining sensor types</b>\n",
    "    <br> <br>\n",
    "      \"[Combining different channel types] requires [...] the re-scaling of the data or sensor type specific values [...]], since different sensor types are measured at different scales (e.g., MEG data from gradiometers are usually in the range of 10−11 T/m and data from magnetometers in the range of 10−13 T). If the data is not scaled, the beamformer solution will be biased towards the sensor type with the larger values. One convenient way to achieve a proper integration of both sensor types is by spatially whitening the forward field and the covariance matrix\" <br>\n",
    "      <br>\n",
    "      Quote from: Westner et al. 2022, <em>A unified view on beamformers for M/EEG source reconstruction</em>, NeuroImage, DOI: 10.1016/j.neuroimage.2021.118789\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Spatial whitening</b>\n",
    "    <br> <br>\n",
    "      \"Whitening, also called pre-whitening, is a linear operation that intends to decorrelate and scale the noise components in the data. The term whitening refers to the color of the noise being white, i.e., having a covariance matrix that equals the Identity matrix. To achieve this, the procedure uses a so-called noise covariance matrix, a channel-level covariance matrix which can be computed on an empty room recording or a pre-stimulus quiescent baseline.\" <br>\n",
    "      <br>\n",
    "      Quote from: Westner et al. 2022, <em>A unified view on beamformers for M/EEG source reconstruction</em>, NeuroImage, DOI: 10.1016/j.neuroimage.2021.118789\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cov = mne.compute_covariance(epochs_meg, tmin=0., tmax=0.15,\n",
    "                                  method='empirical', rank='info')\n",
    "noise_cov = mne.compute_covariance(epochs_meg, tmin=-0.15, tmax=0.,\n",
    "                                   method='empirical', rank='info')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's good practice to visualize our data covariance matrix. The covariance matrices are not whitened yet (this will happen internally in the beamforming step). Thus you can see the different scaling between magnetometers and gradiometers in the plots below!\n",
    "\n",
    "If you want to know more about covariance matrices and their estimation, check out the second section of the `Beamforming_best_practices.ipynb` notebook or the `Working_with_SSSed_data.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.viz.plot_cov(data_cov, info=epochs.info);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute beamformer on MEG data and apply to evoked data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute the beamformer (sometimes also called a spatial filter) and apply it to the evoked. We choose the Linearly Constrained Minimum Variance beamformer (LCMV), which is expecting time-resolved data, such as an evoked potential.\n",
    "\n",
    "We use the following ingredients to compute the beamformer:\n",
    "- _data covariance matrix_: This covariance matrix should represent the data.\n",
    "- _noise covariance matrix_: This covariance matrix should represent \"noise\". It will be used to whiten the data and forward model.\n",
    "- _the data_: The beamformer will be applied to this - we pass in our evoked object we have created above.\n",
    "- _the forward model_: The one we loaded from disk.\n",
    "- _orientation_: We ask the beamformer to compute the source orientations that maximize power for us. That is done using `pick_ori='max-power'`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.beamformer import make_lcmv, apply_lcmv\n",
    "\n",
    "filters = make_lcmv(epochs_meg.info, fwd_meg, data_cov=data_cov, noise_cov=noise_cov, pick_ori='max-power')\n",
    "stc_meg = apply_lcmv(evoked=evoked_meg, filters=filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the brain and time course:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stc_meg.crop(-0.01, 0.15).plot(subjects_dir=subjects_dir, subject='sample', hemi='both');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beamforming with MEG and EEG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sample` data set is a simultaneous MEG and EEG recording. Thus, we can now add the EEG data and beamform the full data set!\n",
    "\n",
    "If you are interested in a closer look at source reconstruction of EEG data, check out the `Source_reconstruction_with_EEG.ipynb` notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MEG-EEG forward model\n",
    "\n",
    "Again, we load the data set from disk. The forward model contains all the information for both MEG sensor types _and_ EEG channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the precomputed EEG forward model from disk\n",
    "fname_fwd = data_path / 'sample_audvis-meg-eeg-oct-6-fwd.fif'\n",
    "fwd_meeg = mne.read_forward_solution(fname_fwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute evoked fields and potentials\n",
    "\n",
    "This time, we do not have to pick the data: we will use all channel types present, MEG and EEG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked = epochs.average()\n",
    "evoked.plot_joint();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute covariance matrices from EEG and MEG data\n",
    "\n",
    "As before, we have to compute the covariance matrices, both the data covariance matrix and the noise covariance matrix required for whitening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cov = mne.compute_covariance(epochs, tmin=0., tmax=0.15,\n",
    "                                  method='empirical', rank='info')\n",
    "noise_cov = mne.compute_covariance(epochs, tmin=-0.15, tmax=0.,\n",
    "                                   method='empirical', rank='info')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute and apply beamformer spatial filter\n",
    "\n",
    "Now, we can compute the beamformer and apply it to the evoked data. We pass the forward model, covariance matrices, and data computed on all channel types. We then can visualize our data the same way as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filters = make_lcmv(epochs.info, fwd_meeg, data_cov=data_cov, noise_cov=noise_cov, pick_ori='max-power')\n",
    "stc_meg = apply_lcmv(evoked=evoked, filters=filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stc_meg.crop(-0.01, 0.15).plot(subjects_dir=subjects_dir, subject='sample', hemi='both');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISES</b>:\n",
    "     <ul>\n",
    "      <li> Do the MEG-EEG results differ much from the MEG results? </li>\n",
    "      <li> The data also contains auditory stimulation. Do you expect auditory potentials/fields to be less or more impacted by adding EEG data into the source reconstruction? You can try this out by changing the trigger value above from 3 (left visual) to 1 (left auditory). </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare sensitivity profiles of forward models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different channel types have different sensitivity profiles. That means they \"see\" (or: measure) different aspects of the source activity. We can visualize this using the forward model.\n",
    "\n",
    "Below, we visualize the sensitvity of the magnetometers and the EEG channels.\n",
    "\n",
    "### Sensitivity of magnetometers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens_map_mag = mne.sensitivity_map(fwd_meeg, ch_type='mag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim = dict(kind='value', lims=(0.0, 0.50, 0.99))\n",
    "brain = sens_map_mag.plot(subject='sample', subjects_dir=subjects_dir,\n",
    "                          clim=clim, smoothing_steps=4,\n",
    "                          time_label='Magnetometer sensitivity');\n",
    "brain.show_view('lat');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensitivity of EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sens_map_eeg = mne.sensitivity_map(fwd_meeg, ch_type='eeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain = sens_map_eeg.plot(subject='sample', subjects_dir=subjects_dir,\n",
    "                          clim=clim, smoothing_steps=4,\n",
    "                          time_label='EEG sensitivity');\n",
    "brain.show_view('lat');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>:\n",
    "     <ul>\n",
    "      <li>Can you justify the claims that MEG is not as sensitive to radial sources as EEG?</li>     \n",
    "      <li>Compute and plot the sensitivity maps for gradiometers and compare it with the magnetometers. Can you spot any differences? </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take home messages\n",
    "\n",
    "Here are the top things to pay special attention to when combining channel types:\n",
    "\n",
    "- Pay attention to the specific requirements of the individual channel types (e.g., using an average reference for EEG data).\n",
    "- Supply the beamformer algorithm with a noise covariance matrix to whiten your data and forward model.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne_berlin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
