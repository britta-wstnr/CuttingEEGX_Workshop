{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the forward model\n",
    "\n",
    "`\n",
    "Authors: Britta Westner\n",
    "`\n",
    "\n",
    "`\n",
    "based on existing tutorials by Alex Gramfort, Eric Larson, and Denis A. Engemann\n",
    "`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial is not as interactive as the others (no exercises). In the context of the CuttingEEGX MNE-Python workshop, it is meant as a resource to check out if you are curious about forward modelling - the workshop is however focused on inverse modelling (source reconstruction).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mne.set_log_level('warning')\n",
    "\n",
    "# set paths:\n",
    "sample_path = mne.datasets.sample.data_path()\n",
    "data_path = sample_path / 'MEG' / 'sample'\n",
    "subjects_dir = sample_path / 'subjects'\n",
    "\n",
    "# path to raw MEG/EEG file:\n",
    "fname_raw = data_path / 'sample_audvis_raw.fif'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the forward operator\n",
    "\n",
    "To compute a forward operator (also known as forward model, gain matrix, or - less accurately - lead field) we need:\n",
    "\n",
    "   - a ``-trans.fif`` file that contains the coregistration information\n",
    "   - a source space\n",
    "   - the BEM surfaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute and visualize BEM surfaces\n",
    "\n",
    "\n",
    "Here, we work with **pre-computed BEM surfaces**. \n",
    "\n",
    "Computing the BEM surfaces requires FreeSurfer (get it at: https://surfer.nmr.mgh.harvard.edu/fswiki/DownloadAndInstall#Download) and makes use of either of the two following command line tools:\n",
    "\n",
    "[mne watershed_bem](http://martinos.org/mne/dev/generated/commands.html#mne-watershed-bem)\n",
    "\n",
    "[mne flash_bem](http://martinos.org/mne/dev/generated/commands.html#mne-flash-bem)\n",
    "\n",
    "Or can be done by directly by calling the functions (FreeSurfer installation needed):\n",
    "\n",
    "https://mne.tools/stable/generated/mne.bem.make_watershed_bem.html\n",
    "\n",
    "https://mne.tools/stable/generated/mne.bem.make_flash_bem.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "If you would like to try out BEM reconstruction for yourself later, you can install FreeSurfer on MacOS or Linux directly and in a VirtualMachine for Windows. \n",
    "\n",
    "To compute BEM models for this dataset,  you set up a `SUBJECTS_DIR` and run:\n",
    "\n",
    "    mne watershed_bem -s sample --overwrite\n",
    "    mne make_scalp_surfaces -s sample --force --overwrite\n",
    "\n",
    "So, let's first look at the BEM surfaces.\n",
    "\n",
    "For EEG we use 3 layers (inner skull, outer skull, and skin), while for MEG 1 layer (inner skull) is enough.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first set the path to the T1\n",
    "t1_fname = subjects_dir / 'sample' / 'mri' / 'T1.mgz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a look at the MRI using `nilearn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from nilearn import plotting\n",
    "plotting.plot_anat(t1_fname);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the BEM model (the identified surfaces of the BEM):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "mne.viz.plot_bem(subject='sample', subjects_dir=subjects_dir,\n",
    "                 mri=t1_fname,\n",
    "                 orientation='coronal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coregistration \n",
    "\n",
    "The next step usually would be to coregister the MRI coordinate system with the MEG coordinate system. This is done to get the sensors into the right relation to the head model for the forward model computation.\n",
    "\n",
    "For this data set, this is already done, but if you wanted to do this, this is the code to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mne.gui.coregistration(subject='sample', subjects_dir=subjects_dir, inst=fname_raw);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the coregistration\n",
    "\n",
    "The coregistration is the operation that allows to position the head and the sensors in a common coordinate system. \n",
    "\n",
    "In the MNE software, the transformation to align the head and the sensors in stored in a so called *trans* file. It is a FIF file that ends with `-trans.fif`. It can be obtained with ``mne_analyze`` (Unix tools), ``mne.gui.coregistration`` (in Python, see above) or mrilab if you're using a Neuromag system.\n",
    "\n",
    "For the Python version, see https://mne.tools/dev/generated/mne.gui.coregistration.html for the docstring. There is also a video link that shows how to perform coregistration.\n",
    "\n",
    "Since we assume the coregistration is done, we just visually check the alignment with the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_fname = data_path / 'sample_audvis_raw-trans.fif'\n",
    "info = mne.io.read_info(fname_raw)\n",
    "fig = mne.viz.plot_alignment(info, trans_fname, subject='sample', dig=True,\n",
    "                             subjects_dir=subjects_dir, verbose=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Source Space\n",
    "\n",
    "The source space defines the positions of the candidate source locations. The following code computes such a source space with an OCT-6 resolution. \n",
    "\n",
    "Note that this is a surface (not volume) source space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.set_log_level('WARNING')\n",
    "subject = 'sample'\n",
    "src = mne.setup_source_space(subject, spacing='oct6',\n",
    "                             subjects_dir=subjects_dir,\n",
    "                             add_dist=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`src` contains two parts, one for the left hemisphere (4098 locations) and one for the right hemisphere (4098 locations).\n",
    "\n",
    "We can visualize the source space together with the head model and also together with the MEG helmet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "mne.viz.plot_alignment(info, trans_fname, subject=subject, dig=False, src=src,\n",
    "                             subjects_dir=subjects_dir, verbose=True, meg=False,\n",
    "                             eeg=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.viz.plot_alignment(info, trans_fname, subject=subject,\n",
    "                       src=src, subjects_dir=subjects_dir, dig=True,\n",
    "                       surfaces=['head-dense', 'white'], coord_frame='meg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute forward solution\n",
    "\n",
    "Now we have all the ingredients to compute the forward solution.\n",
    "\n",
    "To reduce computational load, we'll just compute a single layer BEM\n",
    "(just inner skull) that can then be used for MEG (but not EEG).\n",
    "\n",
    "First, we compute the BEM model using `mne.make_bem_solution()`, then we compute the forward solution using `mne.make_forward_solution()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "conductivity = (0.3,)  # for single layer\n",
    "# conductivity = (0.3, 0.006, 0.3)  # for three layers\n",
    "model = mne.make_bem_model(subject=subject, ico=4,\n",
    "                           conductivity=conductivity,\n",
    "                           subjects_dir=subjects_dir)\n",
    "bem = mne.make_bem_solution(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute the forward model (this might take a while!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwd = mne.make_forward_solution(fname_raw, trans=trans_fname,\n",
    "                                src=src, bem=bem,\n",
    "                                meg=True,  # include MEG channels\n",
    "                                eeg=False,  # exclude EEG channels\n",
    "                                mindist=5.0,  # ignore sources <= 5mm from inner skull\n",
    "                                n_jobs=1)  # number of jobs to run in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadfield = fwd['sol']['data']\n",
    "print(\"Leadfield size : %d sensors x %d dipoles\" % leadfield.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
