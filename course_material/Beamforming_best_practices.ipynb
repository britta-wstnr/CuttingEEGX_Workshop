{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best practices for beamformer source reconstruction\n",
    "\n",
    "\n",
    "`\n",
    "Author: Britta Westner\n",
    "`\n",
    "\n",
    "`\n",
    "parts of this notebook are inspired by the Beamformer tutorial of MNE-Python: https://mne.tools/stable/auto_tutorials/inverse/50_beamformer_lcmv.html#sphx-glr-auto-tutorials-inverse-50-beamformer-lcmv-py\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will have a look at best practices and pitfalls in beamformer source reconstruction. We use the `sample` dataset. \n",
    "\n",
    "The best practices discussed here are relevant knowledge for any beamformer application. Some more specific best practices are discussed in the following notebooks:\n",
    "- Beamforming with EEG data: `Source_reconstruction_with_EEG.ipynb`\n",
    "- Working with Maxwell-filtered data (or otherwise severly rank-deficient data): `Working_with_SSSed_data.ipynb`\n",
    "- Working with multiple channel types at the same time: `Combining_channel_types.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import mne\n",
    "\n",
    "mne.set_log_level('warning')\n",
    "\n",
    "# set paths:\n",
    "sample_path = mne.datasets.sample.data_path()\n",
    "data_path = sample_path / 'MEG' / 'sample'\n",
    "subjects_dir = sample_path / 'subjects'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and epoch data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we read the raw data from disk. We only keep the gradiometer MEG data, as we are not interested in the EEG data for this tutorial and want to keep things simple by only looking at one MEG channel type. We also keep the stim channels, because we still want to cut the data in to epochs later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read raw data\n",
    "fname_raw = data_path / 'sample_audvis_raw.fif'\n",
    "raw = mne.io.read_raw_fif(fname_raw)\n",
    "raw.pick(picks=['mag', 'stim'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create epochs from the continuous data and compute the evoked fields. We use only the epochs that use visual stimulation. From the epochs, we create the evoked fields.\n",
    "\n",
    "We use the epochs where a visual stimulus was presented in the left or right visual field. These have the trigger codes `3` and `4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = mne.find_events(raw)\n",
    "epochs = mne.Epochs(raw, events, event_id=[3, 4])\n",
    "evoked = epochs.average()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the evoked fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked.plot();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare beamforming\n",
    "\n",
    "In the following, we will look at different aspects of beamforming. Let's first make sure we have our two main ingredients ready: the _forward model_ and the _data covariance matrix_.\n",
    "\n",
    "Let's load the forward model - here, we load a _volumetric_ forward model. \n",
    "\n",
    "If you want to learn more about how to compute forward models, check out the notebook `Forward_modelling.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the precomputed MEG forward model from disk\n",
    "fname_fwd = data_path / 'sample_audvis-meg-vol-7-fwd.fif'\n",
    "fwd_meg = mne.read_forward_solution(fname_fwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the computation of the beamformer, we also need a **data covariance matrix**. Let's compute our covariance matrix over the first 150 ms after the stimulus was presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute covariance matrix\n",
    "data_cov = mne.compute_covariance(epochs, tmin=0.0, tmax=0.15, method='empirical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The center-of-head bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first look at something that is called the center-of-head bias. This results from beamforming data _without_ using normalization of either the forward model or beamformer weight or using a contrast between conditions.\n",
    "\n",
    "You will not come across this in MNE-Python with default parameter settings - by default, MNE-Python normalizes the beamformer weights, running a so-called _unit-noise-gain beamformer_. \n",
    "Let's first look at the center-of-head bias and then look at how **normalization** can mitigate it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Center-of-head bias</b>\n",
    "    <br> <br>\n",
    "      \"The magnitude of forward field coefficients decreases with the distance of the dipole (its depth) to the sensors. [... T]he unit-gain beamformer weights, and hence the magnitude of the corresponding beamformer output, depends on the inverse of the forward field matrix at a given dipole location. This so-called center of head bias causes the reconstructed power of sources that are far away from the sensors to be a few orders of magnitude larger than the reconstructed power of more superficial sources. This places restrictions on a direct magnitude-based comparison of the beamformer output across space.\" <br>\n",
    "      <br>\n",
    "      Quote from: Westner et al. 2022, <em>A unified view on beamformers for M/EEG source reconstruction</em>, NeuroImage, DOI: 10.1016/j.neuroimage.2021.118789\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the beamformer and apply it to the evoked fields. We choose the Linearly Constrained Minimum Variance beamformer (LCMV), which is expecting time-resolved data, such as an evoked field.\n",
    "\n",
    "We use the following ingredients to compute the beamformer:\n",
    "- _data covariance matrix_: This covariance matrix should represent the data.\n",
    "- _the data_: The beamformer will be applied to this - we pass in our evoked object we have created above.\n",
    "- _the forward model_: The one we loaded from disk.\n",
    "- _orientation_: We ask the beamformer to compute the source orientations that maximize power for us. That is done using `pick_ori='max-power'`.\n",
    "\n",
    "Crucially, we also choose the following setting:\n",
    "- _weight_norm_: We choose `None` to not use any weight normalization. This corresponds to the _unit-gain_ beamformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.beamformer import make_lcmv, apply_lcmv\n",
    "\n",
    "filters = make_lcmv(epochs.info, fwd_meg, data_cov=data_cov, weight_norm=None, pick_ori='max-power')\n",
    "stc = apply_lcmv(evoked=evoked, filters=filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the brain and time course:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stc.crop(-0.05, 0.15).plot(subjects_dir=subjects_dir, subject='sample', src=fwd_meg['src']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that a lot of the activity is drawn towards the center/bottom of the brain - instead of showing up in the visual cortex as we would expect. The peak time does not match what we would expect from a visually evoked field either.\n",
    "\n",
    "Let's now look at what we get if we compute a weight-normalized beamformer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISES</b>:\n",
    "     <ul>\n",
    "      <li> Change the weight norm parameter to 'unit-noise-gain-invariant'. What differences do you observe? </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data covariance matrices and regularization\n",
    "\n",
    "One ingredient the beamformer relies on to compute its weights is the data covariance matrix. It describes how channel information covaries across time. \n",
    "\n",
    "Certain procedures or circumstances can make the data (and thus the data covariance matrix) rank-deficient. These procedures and circumstances include:\n",
    "- too few independent data points (short experiment, heavy data filtering)\n",
    "- interpolation of channels\n",
    "- cleaning with ICA or similar algorithms\n",
    "- EEG (average) referencing\n",
    "\n",
    "Let's have a closer look at what rank-deficiency means: the **rank** of a matrix is the maximal number of linearly independent columns of this matrix. If you remove (even noise) components from your data, you remove information, but not column or rows (there are still an equal amount of channels and time points present). This makes the data linearly dependent - or: rank deficient.\n",
    "\n",
    "This can be visualized in MNE-Python easily when plotting the data covariance matrix. Let's visualize our covariance matrix!\n",
    "In the singular value plots, you can see a vertical line at the estimated rank of the data. This vertical line coincides with the cliff of the singular value spectrum. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Rank estimation of covariance matrices</b>\n",
    "    <br> <br>\n",
    "      \"It is advisable to check the quality of the data covariance matrix by inspecting the rank and condition number, and also the singular value spectrum of the matrix, which is obtained by a Singular Value Decomposition (SVD). Plotting the singular values on a logarithmic axis provides an indication of the effective numerical rank of the covariance matrix. Typically, the singular value spectrum of an ill-conditioned matrix shows a \"cliff\" at its effective rank, with the numerically irrelevant components having singular values several orders of magnitude smaller than the rest. Sometimes, the spectrum can show two or more such cliffs, e.g., in the case of combined channel types or when the data has been processed with SSS. In such cases, a close inspection of the singular value spectrum is advisable, as conventional rank estimation via SVD can fail.\" <br>\n",
    "      <br>\n",
    "      Quote from: Westner et al. 2022, <em>A unified view on beamformers for M/EEG source reconstruction</em>, NeuroImage, DOI: 10.1016/j.neuroimage.2021.118789\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.viz.plot_cov(data_cov, evoked.info);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISES</b>:\n",
    "     <ul>\n",
    "      <li> By how much is the data rank-deficient? The number of MEG sensors is 102. </li>\n",
    "      <li> Can you find out why the data is rank-deficient? Hint: inspect the info field of the evoked object. </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is this relevant? Well, during the beamformer computation, the inverse of the covariance matrix is taken - and that inverse is ill-defined if the matrix is rank-deficient. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Rank estimation of covariance matrices</b>\n",
    "    <br> <br>\n",
    "      \"If the estimate of the data covariance is unreliable, and thus proves to be ill-conditioned, a simple mathematical inverse of this matrix is either impossible, causing the beamformer computation to fail completely, or the used ill-conditioned covariance matrix will lead to poor beamformer results.\" <br>\n",
    "      <br>\n",
    "      Quote from: Westner et al. 2022, <em>A unified view on beamformers for M/EEG source reconstruction</em>, NeuroImage, DOI: 10.1016/j.neuroimage.2021.118789\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to deal with rank-deficient matrices is Tikhonov regularization. That de-correlates the columns of our rank-deficient covariance matrix by adding to the diagonal. The values to add to the diagonal are expressed as ratios/percentages of the sensor power. \n",
    "\n",
    "In MNE-Python, we use the `reg` parameter for that. By default, the algorithms uses a regularization parameter of 5%: `reg=0.05`. This is what we've silently been doing above. Let's set it to 0% and see what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = make_lcmv(epochs.info, fwd_meg, data_cov=data_cov, pick_ori='max-power', reg=0.0)\n",
    "stc = apply_lcmv(evoked=evoked, filters=filters)\n",
    "stc.crop(-0.05, 0.15).plot(subjects_dir=subjects_dir, subject='sample', src=fwd_meg['src']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, not too much! This is because MNE-Python internally uses a pseudo-inverse, which will deal with small rank-deficiencies. \n",
    "If you want to see a beamformer fail dramatically due to rank-deficiency, head over to the `Working_with_SSSed_data.ipynb` notebook!\n",
    "This notebook also details other ways to deal with rank-deficiency, e.g. spatial whitening and truncated pseudo inverses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISES</b>:\n",
    "     <ul>\n",
    "      <li> The downside of regularization is that it decreases spatial resolution. Can you support this claim by increasing the regularization by a lot? </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Scalar and vector beamformers\n",
    "\n",
    "So far, we have been working with scalar beamformers. They give back one value per source location and time point. Vector beamformers give back three - for the _x_, _y_, and _z_ components of the dipole moment. \n",
    "\n",
    "The scalar beamformer in MNE-Python computes the source orientation per source location which maximizes power. That beamformer is computed by setting `pick_ori` to `'max-power'` as we did above.\n",
    "Let now look at what a vector beamformer output looks like. For that, we first set `pick_ori` to `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = make_lcmv(epochs.info, fwd_meg, data_cov=data_cov, pick_ori=None)\n",
    "stc = apply_lcmv(evoked=evoked, filters=filters)\n",
    "stc.crop(-0.05, 0.15).plot(subjects_dir=subjects_dir, subject='sample', src=fwd_meg['src']);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This beamformer gives back only positive values. Indeed, looking at the help confirms that: `Orientations are pooled after computing a vector beamformer (Default).` Thus, the three orientations that were computed, were later combined into one value.\n",
    "\n",
    "We, however, can also keep those three components separate by setting `pick_ori` to `vector`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = make_lcmv(epochs.info, fwd_meg, data_cov=data_cov, pick_ori='vector')\n",
    "stc_vec = apply_lcmv(evoked=evoked, filters=filters)\n",
    "stc_vec.crop(-0.05, 0.15).plot(subjects_dir=subjects_dir, subject='sample', src=fwd_meg['src']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISES</b>:\n",
    "     <ul>\n",
    "      <li> Compare this plot to the one above. Why is there no difference? </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the three components of the dipole. Let's do that for the peak voxel!\n",
    "\n",
    "This requires some `matplotlib` code - a good exercise :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # we will use Matplotlib for plotting\n",
    "\n",
    "peak_vox, _ = stc_vec.get_peak(vert_as_index=True)  # get the peak voxel index\n",
    "\n",
    "ori_labels = [\"x ori\", \"y ori\", \"z ori\"]  # labels for our plot\n",
    "\n",
    "# loop across the orientations and plot\n",
    "fig, ax = plt.subplots(1)\n",
    "for ori, label in zip(stc_vec.data[peak_vox, :, :], ori_labels):\n",
    "    # we indexed the peak voxel and stored the result in \"ori\":\n",
    "    ax.plot(stc_vec.times, ori, label=f\"{label} component\")\n",
    "\n",
    "# make plot neater:\n",
    "ax.legend(loc=\"lower right\")  # add legend\n",
    "ax.set(\n",
    "    xlabel=\"Time (s)\",\n",
    "    ylabel=\"Amplitude (a.u.)\",\n",
    ");  # labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Common spatial filters\n",
    "\n",
    "Often, we do not want to look at the time course of single condition, but compare conditions. Especially if we statistically compare them, it's important that we use _one_ spatial filter for the source reconstruction of both conditions. This beamformer should be computed using an equal amount of data from both conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Common spatial filters</b>\n",
    "    <br> <br>\n",
    "      \"If a contrast between two conditions is formed, it is good practice to compute the data covariance matrix based on an equal amount of data from both conditions (Gross et al., 2013). This common spatial filter is subsequently applied to each condition separately. This procedure prevents the spatial filter from being skewed and introducing spurious differences among the two conditions.\" <br>\n",
    "      <br>\n",
    "      Quote from: Westner et al. 2022, <em>A unified view on beamformers for M/EEG source reconstruction</em>, NeuroImage, DOI: 10.1016/j.neuroimage.2021.118789\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute a contrast between _activity_ (0.05 to 0.15 sec after stimulus onset) and _baseline_ (-0.15 t0 -0.05 sec relative to stimulus onset). We will compute two covariance matrices and then join them - and compute one _common_ spatial filter from that.\n",
    "We will then apply this common spatial filter to the previously computed covariance matrices. Then we can contrast the obtained source power of _baseline_ and _activity_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_base = mne.compute_covariance(epochs, tmin=-0.15, tmax=-0.05)\n",
    "cov_acti = mne.compute_covariance(epochs, tmin=0.05, tmax=0.15)\n",
    "\n",
    "# combine those two covariance matrices\n",
    "cov_common = cov_base + cov_acti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have learned that it's good practice to look at the covariance matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.viz.plot_cov(cov_common, evoked.info);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now use this common data covariance matrix to create our beamformer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = make_lcmv(epochs.info, fwd_meg, data_cov=cov_common, pick_ori='max-power')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the idea is to apply this spatial filter _twice_: once to the baseline data and once to the activity data. We will apply the spatial filter to the covariance matrices directly - this gives us source power, but no time series. \n",
    "\n",
    "It's of course also possible to apply the spatial filter to the evoked or epochs objects of the baseline and activity data periods!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.beamformer import apply_lcmv_cov\n",
    "stc_base = apply_lcmv_cov(cov_base, filters)\n",
    "stc_acti = apply_lcmv_cov(cov_acti, filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute a contrast between the two source estimates we have obtained. Let's use the baseline estimate to normalize the activity. And then let's plot the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stc_diff = stc_acti.copy()  # we make a copy so you can use the original for further exploration\n",
    "stc_diff /= stc_base\n",
    "\n",
    "stc_diff.plot(subjects_dir=subjects_dir, subject='sample', src=fwd_meg['src']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISES</b>:\n",
    "     <ul>\n",
    "      <li> Can you plot the difference between active and baseline instead? </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reading\n",
    "\n",
    "A whole section of Westner et al. 2022, <em>A unified view on beamformers for M/EEG source reconstruction</em>, NeuroImage, DOI: 10.1016/j.neuroimage.2021.118789 is dedicated to \"Practical considerations and best practices in beamformer source reconstruction\".\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne_berlin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
